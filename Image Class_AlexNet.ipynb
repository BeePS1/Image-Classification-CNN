{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task-3 Image Classifiation (iNaturalist)\n",
        "## Bhanu Pratap Singh (PH20C010)"
      ],
      "metadata": {
        "id": "RgEp6sGGlxOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a AlexNet model with 5 Convolutional layers and 3 fully connected layers. (60M Parameters)"
      ],
      "metadata": {
        "id": "XKhtaoesmKtK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-mNOzBUm1BY"
      },
      "source": [
        "# Imports & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZpBxSYMmzrG"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!wget https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n",
        "!unzip /content/nature_12K.zip\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvB6NNxsnJyi"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "from glob import glob\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oQ_qcF9nxWy"
      },
      "source": [
        "# Dataloader\n",
        "\n",
        "- Dataset Class for Setting up the data loading process\n",
        "- Sections to fill in this script: `_init_transform()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xJnjBM-ntqN"
      },
      "outputs": [],
      "source": [
        "class inaturalist(Dataset):\n",
        "    def __init__(self, root_dir, mode , transform = True):\n",
        "        self.data_dir = root_dir\n",
        "        self.mode = mode\n",
        "        self.transforms = transform      \n",
        "        self._init_dataset()\n",
        "        if transform:\n",
        "            self._init_transform()\n",
        "\n",
        "    def _init_dataset(self):\n",
        "        self.files = []\n",
        "        self.labels = []\n",
        "        dirs = sorted(os.listdir(os.path.join(self.data_dir, 'train')))\n",
        "        if self.mode == 'train': \n",
        "            for dir in range(len(dirs)):\n",
        "                files = sorted(glob(os.path.join(self.data_dir, 'train', dirs[dir], '*.jpg')))\n",
        "                self.labels += [dir]*len(files)            \n",
        "                self.files += files\n",
        "        elif self.mode == 'val':\n",
        "            for dir in range(len(dirs)):\n",
        "                files = sorted(glob(os.path.join(self.data_dir, 'val', dirs[dir], '*.jpg')))\n",
        "                self.labels += [dir]*len(files)            \n",
        "                self.files += files\n",
        "        else:\n",
        "            print(\"No Such Dataset Mode\")\n",
        "            return None\n",
        "        \n",
        "    def _init_transform(self):\n",
        "        # resizing to 227x227\n",
        "        self.transform = transforms.Compose([transforms.Resize((227,227)), transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "            # Useful link for this part: https://pytorch.org/vision/stable/transforms.html\n",
        "        ])\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        img = Image.open(self.files[index]).convert('RGB')\n",
        "        label = self.labels[index]\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        label = torch.tensor(label, dtype = torch.long)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJccgV5Knzi6"
      },
      "source": [
        "# Model\n",
        "\n",
        "- Class to define the model which we will use for training\n",
        "- Stuff to fill in: The Architecture of your model, the `forward` function to define the forward pass\n",
        "\n",
        "NOTE!: You are NOT allowed to use pretrained models for this task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AYXvAZFqkzT"
      },
      "outputs": [],
      "source": [
        "\n",
        "        # Useful Link: https://pytorch.org/docs/stable/nn.html\n",
        "        #------------ENTER YOUR MODEL HERE----------------#  \n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU())\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(9216, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(4096, num_classes))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5h1-WXcsAV0"
      },
      "outputs": [],
      "source": [
        "Alex = Classifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AkrcV9itGM1",
        "outputId": "d4c15b0c-a296-4714-8f32-c6dc51ca33f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
            "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (layer5): Sequential(\n",
            "    (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (fc1): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (fc2): Sequential(\n",
            "    (0): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#To see the structure of our model function.\n",
        "print(Alex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBCH7l47nyo6"
      },
      "outputs": [],
      "source": [
        "#Tried the VGG19 model but takes a lot of time.\n",
        "#VGG_19= [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']\n",
        "#class Classifier(nn.Module):\n",
        " #   def __init__(self, in_channels = 3, n_classes=10):\n",
        "  #      super(Classifier, self).__init__()\n",
        "   #     self.in_channels = in_channels\n",
        "    #    self.n_classes = n_classes\n",
        "     #   self.conv_layers = self.create_conv_layers(VGG_19)\n",
        "      #  self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "       # self.fully_connected_layers = nn.Sequential(\n",
        "        #                                        nn.Linear(in_features = 7*7*512 , out_features = 4096, bias = True),\n",
        "         #                                       nn.ReLU(inplace = True),\n",
        "          #                                      nn.Dropout(p = 0.5),\n",
        "           #                                     nn.Linear(in_features = 4096, out_features = 4096, bias = True),\n",
        "#                                                nn.ReLU(inplace = True),\n",
        "#                                                nn.Dropout(p = 0.5),\n",
        "#                                                nn.Linear(in_features = 4096, out_features = self.n_classes),\n",
        "#                                              )\n",
        "#    def create_conv_layers(self, arch):\n",
        "#      layers = []\n",
        "#      in_channels = self.in_channels\n",
        "#      for layer in arch:\n",
        "#        if(type(layer) == int):\n",
        "#          out_channels = layer\n",
        "#\n",
        "#          layers += [nn.Conv2d(\n",
        "#                            in_channels = in_channels,\n",
        "#                            out_channels = out_channels,\n",
        "#                            kernel_size = 3,\n",
        "#                            stride = 1,\n",
        "#                            padding = 1\n",
        "#                          ),\n",
        "#                  nn.BatchNorm2d(layer),\n",
        "#                  nn.ReLU(inplace = True)\n",
        "#                 ]\n",
        "#          in_channels = layer\n",
        "#        elif(layer == 'M'):\n",
        "#          layers += [nn.MaxPool2d(kernel_size = 2, stride = 2)]\n",
        "#\n",
        "#      return nn.Sequential(*layers)\n",
        "#\n",
        "#\n",
        "#        # Useful Link: https://pytorch.org/docs/stable/nn.html\n",
        "#        #------------ENTER YOUR MODEL HERE----------------#        \n",
        "#\n",
        "#    def forward(self, x):\n",
        "#        #---------Assuming x to be the input to the model, define the forward pass-----------#\n",
        "#        x = self.conv_layers(x)\n",
        "#        x = self.avg_pool(x)\n",
        "#        x = torch.flatten(x, start_dim = 1, end_dim = -1)\n",
        "#        x = self.fully_connected_layers(x)\n",
        "#        return F.softmax(x,dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i3bFLsdoF1_"
      },
      "source": [
        "# Training\n",
        "\n",
        "- Sections to Fill: Define `loss` function, `optimizer` and model, `train` and `eval` functions and the training loop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSnVvW2XoUtS"
      },
      "source": [
        "## Hyperparameters\n",
        "\n",
        "Feel free to change these hyperparams based on your machine's capactiy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOZBwxHUn1jl"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZqeVDE4oZ0H"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dmsg0xP8oYTR"
      },
      "outputs": [],
      "source": [
        "trainset = inaturalist(root_dir='/content/inaturalist_12K', mode='train',transform = True)\n",
        "valset = inaturalist(root_dir='/content/inaturalist_12K', mode = 'val',transform = True)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "valloader = DataLoader(valset, batch_size=32, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBhjYABpobqY"
      },
      "source": [
        "## Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8LY3Yiloe4M"
      },
      "outputs": [],
      "source": [
        "# USEFUL LINK: https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "\n",
        "#---Define the loss function to use, model object and the optimizer for training---#\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "anet= Classifier().to(device)\n",
        "optimizer = torch.optim.Adam(anet.parameters(), lr = learning_rate) #Using Adam Optimizer instead of SDG as it saves time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9bEWwU-ohzG"
      },
      "source": [
        "## Checkpoints\n",
        "\n",
        "To save your model weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6t5vtHaLofac"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = 'checkpoints'\n",
        "if not os.path.isdir(checkpoint_dir):\n",
        "    os.makedirs(checkpoint_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MB63p5mP7j4w"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTLTwpfmopqu"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cM9OFbjjojax"
      },
      "outputs": [],
      "source": [
        "def get_model_summary(model, input_tensor_shape):\n",
        "    summary(model, input_tensor_shape)\n",
        "\n",
        "def accuracy(y_pred, y):\n",
        "    _, predicted = torch.max(y_pred.data, 1)\n",
        "    total = y.size(0)\n",
        "    correct = (predicted == y).sum().item()\n",
        "    return correct/total\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCr-_BHxosFO"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaSzNltYorsv"
      },
      "outputs": [],
      "source": [
        "def train(model, trainloader, optimizer, criterion, device):\n",
        "    '''\n",
        "    Write the function to train the model for one epoch\n",
        "    Feel free to use the accuracy function defined above as an extra metric to track\n",
        "    '''\n",
        "     #------YOUR CODE HERE-----#\n",
        "    for image, label in trainloader:\n",
        "      image = image.to(device)\n",
        "      label = label.to(device)\n",
        "      label=label-1  \n",
        "      #print('t_label_shape',label.shape)\n",
        "      #to make it in range[0,9]\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      output = model(image)\n",
        "      #print('t_output_sahpe',output.shape)\n",
        "      loss = criterion(output, label)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OadZ2Iwmouui"
      },
      "source": [
        "## Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NKlJQpIouM5"
      },
      "outputs": [],
      "source": [
        "def eval(model, dataset, criterion, device):\n",
        "    #------YOUR CODE HERE-----#\n",
        "    '''\n",
        "    Write the function to validate the model after each epoch\n",
        "    Feel free to use the accuracy function defined above as an extra metric to track\n",
        "    '''\n",
        "    with torch.no_grad():\n",
        "      correct=0\n",
        "      total=0\n",
        "      for image, label in dataset:\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "        #to make it in range[0,9]\n",
        "        label=label-1\n",
        "        #print('v_label_shape',label.shape)\n",
        "        outputs = model(image)\n",
        "        \n",
        "        #print('v_output_shape',outputs.shape)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += label.size(0)\n",
        "        correct += (predicted == label).sum().item()\n",
        "        del image, label, outputs\n",
        "        #temp, pred = torch.max(outputs, dim = 1)\n",
        "      print('Accuracy (%)',100*correct/total)\n",
        "    \n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1AIrmEeozK4"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfFkPREqov9j",
        "outputId": "ff1e7390-5cb1-4913-dcd9-4ef43f2fab1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (%) 11.15\n",
            "\n",
            "\n",
            "\n",
            " TIME TAKEN FOR THE EPOCH: 29 mins and 14 seconds\n",
            "Accuracy (%) 11.6\n",
            "\n",
            "\n",
            "\n",
            " TIME TAKEN FOR THE EPOCH: 29 mins and 14 seconds\n",
            "Accuracy (%) 12.15\n",
            "\n",
            "\n",
            "\n",
            " TIME TAKEN FOR THE EPOCH: 33 mins and 39 seconds\n",
            "Accuracy (%) 12.65\n",
            "\n",
            "\n",
            "\n",
            " TIME TAKEN FOR THE EPOCH: 33 mins and 6 seconds\n",
            "Accuracy (%) 11.9\n",
            "\n",
            "\n",
            "\n",
            " TIME TAKEN FOR THE EPOCH: 33 mins and 0 seconds\n",
            "Accuracy (%) 12.55\n",
            "\n",
            "\n",
            "\n",
            " TIME TAKEN FOR THE EPOCH: 33 mins and 0 seconds\n",
            "Accuracy (%) 12.05\n",
            "\n",
            "\n",
            "\n",
            " TIME TAKEN FOR THE EPOCH: 32 mins and 55 seconds\n",
            "Accuracy (%) 12.85\n",
            "\n",
            "\n",
            "\n",
            " TIME TAKEN FOR THE EPOCH: 33 mins and 20 seconds\n",
            "Accuracy (%) 12.9\n",
            "\n",
            "\n",
            "\n",
            " TIME TAKEN FOR THE EPOCH: 33 mins and 11 seconds\n",
            "Accuracy (%) 14.45\n",
            "\n",
            "\n",
            "\n",
            " TIME TAKEN FOR THE EPOCH: 33 mins and 6 seconds\n",
            "OVERALL TRAINING COMPLETE\n"
          ]
        }
      ],
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    start_time = time.monotonic()\n",
        "    \n",
        "    '''\n",
        "    Insert code to train and evaluate the model (Hint: use the functions you previously made :P)\n",
        "    Also save the weights of the model in the checkpoint directory\n",
        "    '''\n",
        "    #------YOUR CODE HERE-----#\n",
        "    train(anet,trainloader, optimizer,criterion, device)\n",
        "\n",
        "    eval(anet, valloader,criterion, device)\n",
        "    \n",
        "\n",
        "    end_time = time.monotonic()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(\"\\n\\n\\n TIME TAKEN FOR THE EPOCH: {} mins and {} seconds\".format(epoch_mins, epoch_secs))\n",
        "    \n",
        "\n",
        "    #To avoid overfitting\n",
        "    #if (acc>=0.80):\n",
        "    #  break\n",
        "\n",
        "print(\"OVERALL TRAINING COMPLETE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJEmmbNqo13e"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Task 3 Bhanu Pratap Singh(PH20C010).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}